---
title: "Data Science Term Project"
author: "CSORNAI, Gyula - 134706"
date: "March 4, 2017"
output: html_document
classoption: landscape
---



## Requirements

* Choose a publicly available dataset with at least 10,000 records and 10 variables.
* Do EDA, data cleaning
* Try several supervised learning methods (and several values for the parameters for each method).
* Do model selection and evaluation properly (train-test or cross validation etc.) Show various diagnostics (e.g. ROC curve for classification etc.)
* Discuss which algorithms work best on your data and possibly why.
* Bonus: Try the algorithms on the raw data without the cleaning. Are the results the same or worse?

## Submitted modeling plan

* RF 
* GBM
* KNN
* LogReg
* Lasso

## Data and origin

### Data description and relevance

Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0)) 
Prediction task is to determine whether a person makes over 50K a year.

### Data source

**Lichman, M. (2013).**   *UCI Machine Learning Repository* [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.

**Donor** 
Ronny Kohavi and Barry Becker 
Data Mining and Visualization 
Silicon Graphics. 

```{r setup, include=FALSE}
## initial cleanup
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)

## libraries
library(pander)
library(ggplot2)

## acquiring data from source
odf<- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data", sep=",", header=FALSE)
testdf <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test", sep=",", header=FALSE)

## The source of multiplot function
## http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/ 

multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}


```

## Exploratory data analysis

* age - The age of the individual
* work_class - The type of employer the individual has
* fnlwgt - The number of people the census takers believe that observation represents
* education - The highest level of education achieved for that individual
* eduY - Highest level of education in numerical form
* mar_stat - Marital status of the individual
* occupation - The occupation of the individual
* relationship -  Contains family relationship values 
* race - descriptions of the individuals race
* sex - Biological Sex in 2 base categories
* cap_gain - Capital gains recorded
* cap_loss - Capital Losses recorded
* hrpw - Hours worked per week
* nat_ctry - Country of origin for person
* mt50K - Whether or not the person makes more than $50,000 per annum income.

### Summary statistics of the data

```{r eda_str, echo=FALSE}

## Feature engineering01 - giving the correct names

fRawHeaderBackfill <- function(f){
  names(f)[names(f)=="V1"] <- 'age'
  names(f)[names(f)=="V2"] <- 'work_class'
  names(f)[names(f)=="V3"] <- 'fnlwgt'
  names(f)[names(f)=="V4"] <- 'education'
  names(f)[names(f)=="V5"] <- 'eduY'
  names(f)[names(f)=="V6"] <- 'mar_stat'
  names(f)[names(f)=="V7"] <- 'occupation'
  names(f)[names(f)=="V8"] <- 'relationship'
  names(f)[names(f)=="V9"] <- 'race'
  names(f)[names(f)=="V10"] <- 'sex'
  names(f)[names(f)=="V11"] <- 'cap_gain'
  names(f)[names(f)=="V12"] <- 'cap_loss'
  names(f)[names(f)=="V13"] <- 'hrpw'
  names(f)[names(f)=="V14"] <- 'nat_ctry'
  names(f)[names(f)=="V15"] <- 'mt50K'
  ##str(f)
  return(f)
}

testdf2 <- subset(testdf, testdf$V1!= "|1x3 Cross validator")
testdf2$V1 <- as.numeric(testdf2$V1)

df <- fRawHeaderBackfill(odf)
tdf <- fRawHeaderBackfill(testdf2)
testdf <- NULL
testdf2<- NULL
odf <- NULL

pander(summary(df))

```

### Data cleaning

* Removing ? values
* Transforming output variable to factor
* Omitting fnlwgt: The number of people the census takers believe that observation represents.

```{r eda_cln, echo=FALSE, include=FALSE}

cdf <- subset(df, df$work_class!=" ?"&
                df$occupation!= " ?" &
                df$nat_ctry != " ?"
                )
ctdf <- subset(tdf, tdf$work_class!=" ?"&
                 tdf$occupation!= " ?" &
                 tdf$nat_ctry != " ?"
)

cdf$mt50K <- as.factor(ifelse(cdf$mt50K == " <=50K",0,1 ))

```

### Data visualization

#### Single distribution of continuous variables

```{r eda_histmpl, echo=FALSE, warning=FALSE, fig.width=10, fig.height=5}

h1 <- ggplot(cdf)+aes(x=age)+
  geom_histogram(bins=50, fill='dodgerblue3')+
  labs(
    title='Age distribution',
    subtitle='50 bins',
    x='Age groups',
    y='# of citizens'
  )+
  theme_bw()

h2 <- ggplot(cdf)+aes(x=eduY)+
  geom_histogram(bins=20, fill='dodgerblue3')+
  labs(
    title='distribution of years of education',
    subtitle='20 bins',
    x='Years spent in education',
    y='# of citizens'
  )+
  theme_bw()

h3 <- ggplot(cdf)+aes(x=cap_gain)+
  geom_histogram(bins=50, fill='dodgerblue3')+
  labs(
    title='Distribution of capital gain',
    subtitle='50 bins',
    x='Capital gain groups',
    y='# of citizens'
  )+
  theme_bw()

h3B <- ggplot(cdf)+aes(x=cap_gain)+
  geom_histogram(bins=50, fill='dodgerblue3')+
  labs(
    title='Distribution of capital log gain',
    subtitle='50 bins',
    x='Capital gain groups of\nnon-zero values - log scale ',
    y='# of citizens'
  )+
  scale_x_log10()+
  theme_bw()

h4 <- ggplot(cdf)+aes(x=cap_loss)+
  geom_histogram(bins=50, fill='dodgerblue3')+
  labs(
    title='Distribution of capital loss',
    subtitle='50 bins',
    x='Capital loss groups',
    y='# of citizens'
  )+
  theme_bw()

h4B <- ggplot(cdf)+aes(x=cap_loss)+
  geom_histogram(bins=50, fill='dodgerblue3')+
  labs(
    title='Distribution of capital log loss',
    subtitle='50 bins',
    x='Capital loss groups of\nnon-zero values - log scale',
    y='# of citizens'
  )+
  scale_x_log10()+
  theme_bw()

multiplot(h1, h2, h3, h3B, h4, h4B, cols=3)


```

#### Single distributions of factors

##### Work and occupation

```{r eda_work, echo=FALSE, warning=FALSE, fig.width=10}

fb1 <- ggplot(cdf)+aes(x=work_class,fill=work_class)+
  geom_bar() +
  labs(
    title='Distribution of different work classifications',
    y='# of citizens',
    x=''
  )+
  theme_bw()+
  theme(legend.position="none")+
  theme(axis.text.x=element_text(angle=-60, hjust=0, size=8))


fb4 <- ggplot(cdf)+aes(x=occupation,fill=occupation)+
  geom_bar() +
  labs(
    title='Distribution of different occupations',
    y='# of citizens',
    x=''
  )+
  theme_bw()+
  theme(legend.position="none")+
  theme(axis.text.x=element_text(angle=-60, hjust=0, size=8))

multiplot(fb1,  fb4, cols=2)


```

##### Education

```{r eda_edu, echo=FALSE, fig.width=10}

ggplot(cdf)+aes(x=education,fill=education)+
  geom_bar() +
  labs(
    title='Distribution of different levels of education',
    y='# of citizens',
    x=''
  )+
  theme_bw()+
  theme(legend.position="none")+
  theme(axis.text.x=element_text(angle=-60, hjust=0, size=8))


```

##### Personal data

```{r eda_pers, echo=FALSE, warning=FALSE, fig.width=10, fig.height=8}

fb3 <- ggplot(cdf)+aes(x=mar_stat,fill=mar_stat)+
  geom_bar() +
  labs(
    title='Distribution of different martial status',
    y='# of citizens',
    x=''
  )+
  theme_bw()+
  theme(legend.position="none")+
  theme(axis.text.x=element_text(angle=-45, hjust=0, size=8))

fb5 <- ggplot(cdf)+aes(x=relationship,fill=relationship)+
  geom_bar() +
  labs(
    title='Distribution of different relationships',
    y='# of citizens',
    x=''
  )+
  theme_bw()+
  theme(legend.position="none")+
  theme(axis.text.x=element_text(angle=-45, hjust=0, size=8))

fb6 <- ggplot(cdf)+aes(x=race,fill=race)+
  geom_bar() +
  labs(
    title='Distribution of different races',
    y='# of citizens',
    x=''
  )+
  theme_bw()+
  theme(legend.position="none")+
  theme(axis.text.x=element_text(angle=-45, hjust=0, size=8))

fb7 <- ggplot(cdf)+aes(x=sex,fill=sex)+
  geom_bar() +
  labs(
    title='Distribution of different sexes',
    y='# of citizens',
    x=''
  )+
  theme_bw()+
  theme(legend.position="none")+
  theme(axis.text.x=element_text(angle=-45, hjust=0, size=8))

multiplot(fb3,fb5, fb6, fb7, cols=2)


```

##### Original nationality

```{r eda_nat, echo=FALSE, warning=FALSE, fig.width=10}

fb8 <- ggplot(cdf)+aes(x=nat_ctry,fill=nat_ctry)+
  geom_bar() +
  labs(
    title='Distribution of different native country',
    y='# of citizens',
    x=''
  )+
  theme_bw()+
  theme(legend.position="none")+
  theme(axis.text.x=element_text(angle=-90, hjust=0, size=8))


fb8B <- ggplot(cdf)+aes(x=nat_ctry,fill=nat_ctry)+
  geom_bar() +
  scale_y_log10()+
  labs(
    title='Distribution of different native country',
    subtitle='Y axis on logarytmic scale',
    y='# of citizens\nlog',
    x=''
  )+
  theme_bw()+
  theme(legend.position="none")+
  theme(axis.text.x=element_text(angle=-90, hjust=0, size=8))

multiplot(fb8, fb8B, cols=2)


```

#### Wage category - the future prediction outcome

```{r eda_y, echo=FALSE, warning=FALSE, fig.width=10}

ggplot(cdf)+aes(x=mt50K,fill=mt50K)+
  geom_bar()+
  labs(
    title='Distribution of wage categories',
    subtitle='The output vairable of the modeling',
    y='# of citizens',
    x='Is the annual wage more than 50,000 USD?'
  )+
  theme_bw()+
  theme(legend.position="none")

```

### Joint distributions of different variables

#### Discrete variables

```{r eda_jdisc, echo=FALSE, warning=FALSE, fig.width=10, fig.height=12}

jd1<- ggplot(cdf)+aes(x=education, y=occupation)+
  geom_count(col='dodgerblue3')+
  labs(
    title='Joint distribution of levels of education\nand occupation',
    y='Occupation',
    x='level of education'
  )+
  theme_bw()+
  theme(axis.text.x=element_text(angle=-90, hjust=0, size=8))

jd2<- ggplot(cdf)+aes(x=relationship, y=occupation)+
  geom_count(col='dodgerblue3')+
  labs(
    title='Joint distribution of relationship status\nand occupation',
    y='Occupation',
    x='relationship status'
  )+
  theme_bw()+
  theme(axis.text.x=element_text(angle=-90, hjust=0, size=8))
  
jd3 <- ggplot(cdf)+aes(x=education, y=work_class)+
  geom_count(col='dodgerblue3')+
  labs(
    title='Joint distribution of education\nand occupation',
    y='Work class',
    x='level of education'
  )+
  theme_bw()+
  theme(axis.text.x=element_text(angle=-90, hjust=0, size=8))

jd4 <- ggplot(cdf)+aes(x=mar_stat, y=relationship)+
  geom_count(col='dodgerblue3')+
  labs(
    title='Joint distribution of martial status\nand relationship',
    y='Relationship',
    x='martial status'
  )+
  theme_bw()+
  theme(axis.text.x=element_text(angle=-90, hjust=0, size=8))

multiplot(jd1, jd2, jd3, jd4, cols=2)


```

#### Continuous variables

##### Dependencies between age and capital by sex


```{r eda_jcdist_sex,echo=FALSE, warning=FALSE, fig.width=10, fig.height=9}

jdc1 <- ggplot(cdf)+aes(x=age, y=log(cap_gain+1))+
  geom_bin2d()+
  scale_fill_gradientn(limits=c(1600,0),  colours=rainbow(4))+
  facet_wrap(~sex)+
  labs(
    title='Joint distribution of age and capital gain',
    subtitle='Faceted by sex',
    y='Capital gain\non log scale',
    x='Age'
  )+
  theme_bw()

jdc2 <- ggplot(cdf)+aes(x=age, y=log(cap_loss+1))+
  geom_bin2d()+
  scale_fill_gradientn(limits=c(1600,0),  colours=rainbow(4))+
  facet_wrap(~sex)+
  labs(
    title='Joint distribution of age and capital loss',
    subtitle='Faceted by sex',
    y='Capital loss\non log scale',
    x='Age'
  )+
  theme_bw()

multiplot(jdc1, jdc2, cols=1)


```

##### Dependencies between age and capital gain by work class

```{r eda_jdist_gain_workclass, echo=FALSE, warning=FALSE, fig.width=10, fig.height=9}
ggplot(cdf)+aes(x=age, y=log(cap_gain+1))+
  geom_bin2d()+
  scale_fill_gradientn(limits=c(1600,0),  colours=rainbow(4))+
  facet_wrap(~work_class)+
  labs(
    title='Joint distribution of age and capital gain',
    subtitle='Faceted by work class',
    y='Capital gain\non log scale',
    x='Age'
  )+
  theme_bw()

```

##### Dependencies between age and capital loss by work class

```{r eda_jdist_loss_workclass, echo=FALSE, warning=FALSE, fig.width=10, fig.height=9}
ggplot(cdf)+aes(x=age, y=log(cap_loss+1))+
  geom_bin2d()+
  scale_fill_gradientn(limits=c(1600,0),  colours=rainbow(4))+
  facet_wrap(~work_class)+
  labs(
    title='Joint distribution of age and capital loss',
    subtitle='Faceted by work class',
    y='Capital loss\non log scale',
    x='age'
  )+
  theme_bw()

```

##### Dependencies between age and capital loss by education

```{r eda_jdist_gain_education, echo=FALSE, warning=FALSE, fig.width=10, fig.height=9}
ggplot(cdf)+aes(x=age, y=log(cap_gain+1))+
  geom_bin2d()+
  scale_fill_gradientn(limits=c(900,0),  colours=rainbow(4))+
  facet_wrap(~education)+
  labs(
    title='Joint distribution of age and capital gain',
    subtitle='Faceted by education',
    y='Capital gain\non log scale',
    x='Age'
  )+
  theme_bw()



```

```{r eda_jdist_loss_education, echo=FALSE, warning=FALSE, fig.width=10, fig.height=9}

ggplot(cdf)+aes(x=age, y=log(cap_loss+1))+
  geom_bin2d()+
  scale_fill_gradientn(limits=c(900,0),  colours=rainbow(4))+
  facet_wrap(~education)+
  labs(
    title='Joint distribution of age and capital gain',
    subtitle='Faceted by education',
    y='Capital loss\non log scale',
    x='Age'
  )+
  theme_bw()

```

### Further feature engineering

I am dgoint to transform the capital gain and loss values in the following way:

$$ lncg = log(capgain+1) $$
AND

$$ lncl = log(caploss+1) $$

in order to normalize the distribution of the values. This is not a fundamental error, because the majority of the observed citizens have 0 capital gain and 0 capital loss, and whoever has some, has so much, that 1 USD per annum does not really count.

From this point on I will analyze the 2 versions separately, until I can figure it out, whether this transformation has helped or not.

```{r eda_fteng_inc, echo=TRUE}
cdf$fnlwgt <- NULL
cdf$rnd <-runif(nrow(cdf))
cdf <- cdf[order(cdf$rnd),]
cdf$rnd <- NULL
cdfm <- cdf 
cdfm$lncg <- log(cdfm$cap_gain + 1)
cdfm$lncl <- log(cdfm$cap_loss + 1)
cdfm$cap_gain <- NULL
cdfm$cap_loss <- NULL


```


## Supervised learning methods

```{r model_setup,echo=FALSE, warning=FALSE, include=FALSE, error=FALSE}

library(randomForest)
#install.packages('ROCR')
library(ROCR)
#70% training set 30% test set
train_nolog <- cdf[0:round( nrow(cdf) * 0.7 ),]
train_log <- cdfm[0:round( nrow(cdfm) * 0.7 ),]
test_nolog <- cdf[(round( nrow(cdf) * 0.7 )+1) : nrow(cdf),]
test_log <- cdfm[(round( nrow(cdfm) * 0.7 )+1) : nrow(cdfm),]


```

### Analysis with Random forest

#### Modeling with 100 trees

##### Model details

The following chart shows the model details. The confusion matrix is not very descriptive, as it shows accuracy on the training set. 

I acknowledge, that classification error is very low, in case the model predicts lower annual wage, than 50,000 USD, and it is significantly high, in case it tries to predict higher wage, than 50,000 USD. OBB estimate of error rate is relatively low.

```{r mod_rf_t100_smry, echo=FALSE}

#Random forest on no log, 100 trees
rfmod_t100n <- randomForest(mt50K ~ .,data=train_nolog,ntree=100, importance=TRUE)
#Model details
pander(rfmod_t100n)

```

##### Model accuracy

```{r mod_rf_t100_acc, echo=FALSE, warning=FALSE}
#Model validation 
phat <- predict(rfmod_t100n, test_nolog, type = "prob")[,"1"]
#Error rate
error_rate_rf_t100 <- sum(ifelse(phat>0.5,1,0)!=test_nolog$mt50K)/nrow(test_nolog)

```

Confusion matrix below shows, that the actual prediction on the training set is relatively good: the total error rate is `r error_rate_rf_t100*100`%.

```{r mod_rf_t100_confm,echo=FALSE, warning=FALSE}

#Confusion matrix
pander(table(ifelse(phat>0.5,1,0),test_nolog$mt50K))

```

```{r mod_rf_t100_dtl, echo=FALSE, warning=FALSE}

#ROC
rocr_obj <- prediction(phat, test_nolog$mt50K)
#cutoff vs error rate
proc <- performance(rocr_obj, "err")

#AUC
rf_t100_auc <- performance(rocr_obj, "auc")@y.values[[1]]    # AUC
```

The following charts show the details of the modeling with random forest.
The importance of the variable chart (left upper corner) shows, that the most important predictors are 

* relationship 
* capital gain (level!)
* occupation

variables.
The least important are:

* race
* sex
* original country where citizen came from.

The AUC is `r rf_t100_auc`, which is an acceptable model.

```{r mod_rf_t100_viz, echo=FALSE, warning=FALSE, fig.width=10, fig.height=8}

layout(matrix(c(1,2,3,2), 2, 2 , byrow = TRUE),
       widths=c(1,2))
#Importance of variables
varImpPlot(rfmod_t100n, type=2)
#ROC curve
plot(performance(rocr_obj, "tpr", "fpr"), colorize=TRUE)
plot(proc)

```

#### Modeling multiple random forest model versions

```{r mod_rf_variants1, echo=FALSE}

#Random forest on log, 100 trees
rfmod_t100l <- randomForest(mt50K ~ .,data=train_log,ntree=100, importance=TRUE)
phat2 <- predict(rfmod_t100l, test_log, type = "prob")[,"1"]
mod_rf_t100_log_errorrate <- sum(ifelse(phat2>0.5,1,0)!=test_log$mt50K)/nrow(test_log)
rocr_obj2 <- prediction(phat2, test_log$mt50K)
auc2 <- performance(rocr_obj2, "auc")@y.values[[1]]   

```

```{r mod_rf_variants2, echo=FALSE}
#Random forest on level, 500 trees
rfmod_t500n <- randomForest(mt50K ~ .,data=train_nolog,ntree=500, importance=TRUE)
phat3 <- predict(rfmod_t500n, test_nolog, type = "prob")[,"1"]
mod_rf_t500_nolog_errorrate <- sum(ifelse(phat3>0.5,1,0)!=test_nolog$mt50K)/nrow(test_nolog)
rocr_obj3 <- prediction(phat3, test_nolog$mt50K)
auc3 <- performance(rocr_obj3, "auc")@y.values[[1]] 
```

```{r mod_rf_variants3, echo=FALSE}
#Random forest on log, 500 trees
rfmod_t500l <- randomForest(mt50K ~ .,data=train_log,ntree=500, importance=TRUE)
phat4 <- predict(rfmod_t500l, test_log, type = "prob")[,"1"]
mod_rf_t500_log_errorrate <- sum(ifelse(phat4>0.5,1,0)!=test_log$mt50K)/nrow(test_log)
rocr_obj4 <- prediction(phat4, test_log$mt50K)
auc4 <- performance(rocr_obj4, "auc")@y.values[[1]]
```

```{r mod_rf_variants3Btable, echo=FALSE}

rft3<-table(ifelse(phat4>0.5,1,0), test_nolog$mt50K)
```

```{r mod_rf_variants4, echo=FALSE}
#Random forest on level, 500 trees, 5 variables
rfmod_t500n5 <- randomForest(mt50K ~ .,data=train_nolog,ntree=500, mtry=5, importance=TRUE)
phat5 <- predict(rfmod_t500n5, test_nolog, type = "prob")[,"1"]
mod_rf_t500_nolog_var5_errorrate <- sum(ifelse(phat5>0.5,1,0)!=test_nolog$mt50K)/nrow(test_nolog)
rocr_obj5 <- prediction(phat5, test_nolog$mt50K)
auc5 <- performance(rocr_obj5, "auc")@y.values[[1]] 
```

```{r mod_rf_variants5, echo=FALSE}
#Random forest on log, 500 trees, 5 variables
rfmod_t500l5 <- randomForest(mt50K ~ .,data=train_log,ntree=500, mtry=5, importance=TRUE)
phat6 <- predict(rfmod_t500l5, test_log, type = "prob")[,"1"]
mod_rf_t500_log_var5_errorrate <- sum(ifelse(phat6>0.5,1,0)!=test_log$mt50K)/nrow(test_log)
rocr_obj6 <- prediction(phat6, test_log$mt50K)
auc6 <- performance(rocr_obj6, "auc")@y.values[[1]]

```

##### Comparison chart

|Model version / Performance          |Error rate                                 |AUC             |
|:-----------------------------------:|:-----------------------------------------:|:--------------:|
|RF, ntree=100, cap.level, variable=3 |`r error_rate_rf_t100*100`%                |`r rf_t100_auc` |
|RF, ntree=100, cap.log, variable=3   |`r mod_rf_t100_log_errorrate*100`%         |`r auc2`        |
|RF, ntree=500, cap.level, variable=3 |`r mod_rf_t500_nolog_errorrate*100`%       |`r auc3`        |
|RF, ntree=500, cap.log, variable=3   |`r mod_rf_t500_log_errorrate*100`%         |`r auc4`        |
|RF, ntree=500, cap.level, variable=5 |`r mod_rf_t500_nolog_var5_errorrate*100`%  |`r auc5`        |
|RF, ntree=500, cap.log, variable=5   |`r mod_rf_t500_log_var5_errorrate*100`%    |`r auc6`        |


##### Kernel density functions

The kernel density functions show the probability density of the 2 predictions based on scores.

```{r mod_rf_variants_kd, echo=FALSE, fig.width=10, fig.height=8}

d_phat <- data.frame(phat, mt50K = test_nolog$mt50K)
kdplot1 <- ggplot(d_phat) +
  geom_density( aes(x = phat, fill = mt50K, col=mt50K), alpha=0.4)+
  labs(
    title='Kernel density - RF_t100_v3_level',
    x='Score',
    y='Density'
  )+
  theme_bw()

d_phat2 <- data.frame(phat2, mt50K = test_log$mt50K)
kdplot2 <- ggplot(d_phat2) +
  geom_density( aes(x = phat, fill = mt50K, col=mt50K), alpha=0.4)+
  labs(
    title='Kernel density - RF_t100_v3_log',
    x='Score',
    y='Density'
  )+
  theme_bw()

d_phat3 <- data.frame(phat3, mt50K = test_nolog$mt50K)
kdplot3 <- ggplot(d_phat3) +
  geom_density( aes(x = phat, fill = mt50K, col=mt50K), alpha=0.4)+
  labs(
    title='Kernel density - RF_t500_v3_level',
    x='Score',
    y='Density'
  )+
  theme_bw()

d_phat4 <- data.frame(phat4, mt50K = test_log$mt50K)
kdplot4 <- ggplot(d_phat4) +
  geom_density( aes(x = phat, fill = mt50K, col=mt50K), alpha=0.4)+
  labs(
    title='Kernel density - RF_t500_v3_log',
    x='Score',
    y='Density'
  )+
  theme_bw()

d_phat5 <- data.frame(phat5, mt50K = test_nolog$mt50K)
kdplot5 <- ggplot(d_phat5) +
  geom_density( aes(x = phat, fill = mt50K, col=mt50K), alpha=0.4)+
  labs(
    title='Kernel density - RF_t500_v5_level',
    x='Score',
    y='Density'
  )+
  theme_bw()

d_phat6 <- data.frame(phat6, mt50K = test_log$mt50K)
kdplot6 <- ggplot(d_phat6) +
  geom_density( aes(x = phat, fill = mt50K, col=mt50K), alpha=0.4)+
  labs(
    title='Kernel density - RF_t500_v5_log',
    x='Score',
    y='Density'
  )+
  theme_bw()

multiplot(kdplot1, kdplot2, kdplot3, kdplot4, kdplot5, kdplot6, cols = 3)

```

##### Importance of variables


```{r mod_rf_variants_imp, echo=FALSE, fig.width=10, fig.height=8}
par(mfrow=c(2,3))
varImpPlot(rfmod_t100n, type=2)
varImpPlot(rfmod_t100l, type=2)
varImpPlot(rfmod_t500n, type=2)
varImpPlot(rfmod_t500l, type=2)
varImpPlot(rfmod_t500n5, type=2)
varImpPlot(rfmod_t500l5, type=2)


```

#### Conclusion for Random Forest

* The Random Forest algorythm gives acceptable quality, roboust results for all parameters.
* It does not really matter whether I use log or level value of capital gain
* In all versions the 2 major performance descriptors (error rate and AUC) were very close for each versions
* There is no visual difference in the kernel density functions
* All versions highlighted the same 3 variables as the most important, and the same 3 as the least important, only the importance was slightly different

### Analysis with GBM

Before modeling it is important to transform the output variable to number, because GBM can use numbers only.

```{r setup_gbm, echo=FALSE, include=FALSE, warning=FALSE}

library(gbm)
set.seed(123)
train_nolog$mt50K <- ifelse(train_nolog$mt50K==1, 1, 0)
test_nolog$mt50K <- ifelse(test_nolog$mt50K==1, 1, 0) 

```

#### Primary model

The primary model uses the following parameters:

* Number of trees = 100 
* interaction depth = 10 - The depth of each tree
* shrinkage = 0.01 - Step size reduction in learning while descending on the error rate surface. 1 is full step. Typical shrinkage rates recommended are 0.01 to 0.001
* cv.folds = 5 - Uses 5 fold cross validation
* distribution = *bernoulli* - the loss function

Not yet used

* bag.fraction - subsampling rate

##### Confusion matrix

```{r gbm_primary_confmat, echo=FALSE, warning=FALSE}
gbm_p1 <- gbm(mt50K ~ . ,data=train_nolog, distribution = "bernoulli",
          n.trees = 100, interaction.depth = 10, shrinkage = 0.01, cv.folds = 5)

yhat <- predict(gbm_p1, test_nolog, n.trees = 100) 

pander(table(ifelse(yhat>0,1,0), test_nolog$mt50K))

```

##### Learning curve

```{r gbm_promary_pcurve, echo=FALSE, warning=FALSE}
gbm.perf(gbm_p1, plot.it = TRUE)

```

#### Grid search with different parameters

```{r gbm_grid_srch_tbl1, echo=FALSE}

t1 <- table(ifelse(yhat>0,1,0), test_nolog$mt50K)

```

```{r gbm_grid_srch_tbl2, echo=FALSE}
gbm_500_10_001_5 <- gbm(mt50K ~ . ,data=train_nolog, distribution = "bernoulli", n.trees = 500, interaction.depth = 10, shrinkage = 0.01, cv.folds = 5)
yhat2 <- predict(gbm_500_10_001_5, test_nolog, n.trees = 500) 
t2<- table(ifelse(yhat2>0,1,0), test_nolog$mt50K)

```

```{r gbm_grid_srch_tbl3, echo=FALSE}

gbm_100_20_001_5 <- gbm(mt50K ~ . ,data=train_nolog, distribution = "bernoulli", n.trees = 100, interaction.depth = 20, shrinkage = 0.01, cv.folds = 5)
yhat3 <- predict(gbm_100_20_001_5, test_nolog, n.trees = 100) 
t3<- table(ifelse(yhat3>0,1,0), test_nolog$mt50K)

```

```{r gbm_grid_srch_tbl4, echo=FALSE}
gbm_500_20_001_5 <- gbm(mt50K ~ . ,data=train_nolog, distribution = "bernoulli", n.trees = 500, interaction.depth = 20, shrinkage = 0.01, cv.folds = 5)
yhat4 <- predict(gbm_500_20_001_5, test_nolog, n.trees = 500) 
t4<- table(ifelse(yhat4>0,1,0), test_nolog$mt50K)

```

```{r gbm_grid_srch_tbl6, echo=FALSE}
gbm_500_10_0001_5 <- gbm(mt50K ~ . ,data=train_nolog, distribution = "bernoulli", n.trees = 500, interaction.depth = 10, shrinkage = 0.001, cv.folds = 5)
yhat6 <- predict(gbm_500_10_0001_5, test_nolog, n.trees = 500) 
t6<- table(ifelse(yhat6>0,1,0), test_nolog$mt50K)

```

```{r gbm_grid_srch_tbl8, echo=FALSE}

gbm_500_20_0001_5 <- gbm(mt50K ~ . ,data=train_nolog, distribution = "bernoulli", n.trees = 500, interaction.depth = 20, shrinkage = 0.001, cv.folds = 5)
yhat8 <- predict(gbm_500_20_0001_5, test_nolog, n.trees = 500) 
t8<- table(ifelse(yhat8>0,1,0), test_nolog$mt50K)

```

##### Grid search table

|ModelID|Number of trees|Depth of each tree|Shrinkage|CV folds|Result TN  |Result FN  |Result FP  |Result TP  |Error rate                                 |
|:-----:|:-------------:|:----------------:|:-------:|:------:|:---------:|:---------:|:---------:|:---------:|:-----------------------------------------:|
|gbm_p1 |100            |10                |0.01     |5       |`r t1[1,1]`|`r t1[1,2]`|`r t1[2,1]`|`r t1[2,2]`|`r (t1[1,2]+t1[2,1])/nrow(test_nolog)*100`%|
|gbm_500_10_001_5|500   |10                |0.01     |5       |`r t2[1,1]`|`r t2[1,2]`|`r t2[2,1]`|`r t2[2,2]`|`r (t2[1,2]+t2[2,1])/nrow(test_nolog)*100`%|
|gbm_100_20_001_5|100   |20                |0.01     |5       |`r t3[1,1]`|`r t3[1,2]`|`r t3[2,1]`|`r t3[2,2]`|`r (t3[1,2]+t3[2,1])/nrow(test_nolog)*100`%|
|gbm_500_20_001_5|500   |20                |0.01     |5       |`r t4[1,1]`|`r t4[1,2]`|`r t4[2,1]`|`r t4[2,2]`|`r (t4[1,2]+t4[2,1])/nrow(test_nolog)*100`%|
|gbm_100_10_0001_5|100  |10                |0.001    |5       |6763       |2286       |NA         |NA         |No positive results                        |
|gbm_500_10_0001_5|500  |10                |0.001    |5       |`r t6[1,1]`|`r t6[1,2]`|`r t6[2,1]`|`r t6[2,2]`|`r (t6[1,2]+t6[2,1])/nrow(test_nolog)*100`%|
|gbm_100_20_0001_5|100  |20                |0.001    |5       |6763       |2286       |NA         |NA         |No positive results                        |
|gbm_500_20_0001_5|500  |20                |0.001    |5       |`r t8[1,1]`|`r t8[1,2]`|`r t8[2,1]`|`r t8[2,2]`|`r (t8[1,2]+t8[2,1])/nrow(test_nolog)*100`%|

##### Changing cross validation parameters

```{r gbm_crossval_eff01, echo=FALSE}
gbm_500_20_001_1 <- gbm(mt50K ~ . ,data=train_nolog, distribution = "bernoulli", n.trees = 500, 
                        interaction.depth = 20, shrinkage = 0.01, cv.folds = 1)
yhat11 <- predict(gbm_500_20_001_1, test_nolog, n.trees = 500) 
t11<- table(ifelse(yhat11>0,1,0), test_nolog$mt50K)

```


```{r gbm_crossval_eff02, echo=FALSE}
gbm_500_20_001_10 <- gbm(mt50K ~ . ,data=train_nolog, distribution = "bernoulli", n.trees = 500, 
                        interaction.depth = 20, shrinkage = 0.01, cv.folds = 10)
yhat12 <- predict(gbm_500_20_001_10, test_nolog, n.trees = 500) 
t12<- table(ifelse(yhat12>0,1,0), test_nolog$mt50K)
```

```{r gbm_crossval_eff03, echo=FALSE}
gbm_500_20_001_3 <- gbm(mt50K ~ . ,data=train_nolog, distribution = "bernoulli", n.trees = 500, 
                         interaction.depth = 20, shrinkage = 0.01, cv.folds = 3)
yhat13 <- predict(gbm_500_20_001_3, test_nolog, n.trees = 500) 
t13<- table(ifelse(yhat12>0,1,0), test_nolog$mt50K)
```

The following chart shows the impact of changing the folds of cross validation for the best model.
|ModelID        |Number of trees|Depth of each tree|Shrinkage|CV folds|Result TN  |Result FN  |Result FP  |Result TP  |Error rate                                 |
|:-------------:|:-------------:|:----------------:|:-------:|:------:|:---------:|:---------:|:---------:|:---------:|:-----------------------------------------:|
|gbm_500_20_001_5|500           |20                |0.01     |5       |`r t4[1,1]`|`r t4[1,2]`|`r t4[2,1]`|`r t4[2,2]`|`r (t4[1,2]+t4[2,1])/nrow(test_nolog)*100`%|
|gbm_500_20_001_1|500           |20                |0.01     |1 |`r t11[1,1]`|`r t11[1,2]`|`r t11[2,1]`|`r t11[2,2]`|`r (t11[1,2]+t11[2,1])/nrow(test_nolog)*100`%|
|gbm_500_20_001_10|500          |20                |0.01     |10|`r t12[1,1]`|`r t12[1,2]`|`r t12[2,1]`|`r t12[2,2]`|`r (t12[1,2]+t12[2,1])/nrow(test_nolog)*100`%|
|gbm_500_20_001_3|500           |20                |0.01     |3 |`r t13[1,1]`|`r t13[1,2]`|`r t13[2,1]`|`r t13[2,2]`|`r (t13[1,2]+t13[2,1])/nrow(test_nolog)*100`%|

### Analysis with KNN

K-NearestNeighbour classification algorythm is a bit different from the tree models above, because it can handle only numeric input vectors. It uses Eucledian distance measure thereafter to calculate the "distance of the neighborhood".
From the other side it uses a factor for classification.

```{r knn_setup, echo=FALSE, warning=FALSE}

library(class)
train_nolog$mt50K <- as.factor(train_nolog$mt50K)
test_nolog$mt50K <- as.factor(test_nolog$mt50K)

cdf2 <- cdf

cdf2$work_class <- as.numeric(cdf2$work_class)
cdf2$education <- as.numeric(cdf2$education )
cdf2$mar_stat <- as.numeric(cdf2$mar_stat)
cdf2$occupation <- as.numeric(cdf2$occupation)
cdf2$relationship <- as.numeric(cdf2$relationship)
cdf2$race <- as.numeric(cdf2$race)
cdf2$sex <- as.numeric(cdf2$sex)
cdf2$nat_ctry <- as.numeric(cdf2$nat_ctry)
cdf2$rnd <- NULL

train_nolog2 <- cdf2[0:round( nrow(cdf2) * 0.7 ),]
test_nolog2 <- cdf2[(round( nrow(cdf2) * 0.7 )+1) : nrow(cdf2),]
```


### 2-NN

The following table shows the confusion matrix, using the same (but transformed) train and test sets, using the 2 nearest neighbors for prediction.

```{r knn_2nn, echo=FALSE, warning=FALSE}
fit2 <- knn(train_nolog2[,1:13], test_nolog2[,1:13], train_nolog2$mt50K, k = 2, prob=TRUE)
t2nn <- table(test_nolog2$mt50K,fit2)
pander(t2nn)
```

### 7-NN

The following table shows the confusion matrix, using the same (but transformed) train and test sets, using the 7 nearest neighbors for prediction.

```{r knn_7nn, echo=FALSE, warning=FALSE}
fit7 <- knn(train_nolog2[,1:13], test_nolog2[,1:13], train_nolog2$mt50K, k = 7, prob=TRUE)
t7nn <- table(test_nolog2$mt50K,fit7)
pander(t7nn)
```


### 13-NN

The following table shows the confusion matrix, using the same (but transformed) train and test sets, using the 13 nearest neighbors for prediction.


```{r knn_13nn, echo=FALSE, warning=FALSE}
fit13 <- knn(train_nolog2[,1:13], test_nolog2[,1:13], train_nolog2$mt50K, k = 13, prob=TRUE)
t13nn <- table(test_nolog2$mt50K,fit13)
pander(t13nn)

```

### Conclusion of KNN modeling

The following chart shows the results of the models. 2 neighbours show a higher error rate, however there is small difference between 7 and 13 neighbors. On this specific database KNN algorythm has produced surprisingly good results, despite of the fact that there was no real feature engineering and analysis how the distances between factor levels translate to Eucledian distance.

|Number of neighbors|Result TN     |Result FN     |Result FP    |Result TP    |Error rate                                      |
|:-----------------:|:------------:|:------------:|:-----------:|:-----------:|:----------------------------------------------:|
|2                  |`r t2nn[1,1]` |`r t2nn[1,1]` |`r t2nn[1,1]`|`r t2nn[1,1]`|`r (t2nn[1,2]+t2nn[2,1])/nrow(test_nolog)*100`% |
|7                  |`r t7nn[1,1]` |`r t7nn[1,1]` |`r t7nn[1,1]`|`r t7nn[1,1]`|`r (t7nn[1,2]+t7nn[2,1])/nrow(test_nolog)*100`% |
|13                 |`r t13nn[1,1]`|`r t13nn[1,1]`|`r t13nn[1,1]`|`r t13nn[1,1]`|`r (t13nn[1,2]+t13nn[2,1])/nrow(test_nolog)*100`% |

## Model selection

* All 3 models have produced relatively good resutls during the modeling on this classification use-case on this dataset
* GBM with appropriate parametering has performed a little better in terms of error rate
* My GBM and Random forest models have produced more false positives, KNN has produced more false negatives in general
* The model selection would depend on the use case, specifically
  + The expected true positive/false positive ratio
  + The cost of false positive vs false negative 
  + The environment where the prediction needs to be executed
  
|Best model of genere with parameters       |Error rate                         |FN/FP ratio            |TP/FP ratio             |
|:-----------------------------------------:|:---------------------------------:|:---------------------:|:----------------------:|
|RF, ntree=500, cap.log, variable=3         |`r mod_rf_t500_log_errorrate*100`% |`r rft3[1,2]/rft3[2,1]`|`r rft3[2,2]/rft3[2,1]` |
|GBM, ntree=500, int.depth=20, shrinkage=0.01, cv =5fold|`r (t4[1,2]+t4[2,1])/nrow(test_nolog)*100`%|`r t4[1,2]/t4[2,1]`|`r t4[2,2]/t4[2,1]` |
|KNN, n=13         |`r (t13nn[1,2]+t13nn[2,1])/nrow(test_nolog)*100`%  |`r t13nn[1,2]/t13nn[2,1]`|`r t13nn[2,2]/t7nn[2,1]` |


## Discussion of effectiveness

* Random forest was a bit inaccurate, but was able to run on the dataset without issues (note: no factors have exceeded 53, which is RF limitation)
* GBM was the most accurate, but the cost was more feature engineering and in some cases model was not able to predict positive outcome
* KNN was the fastest to give results, but I did not run into issues with the distance measures





